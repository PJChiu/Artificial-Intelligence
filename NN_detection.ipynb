{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAJWCXumlWBurCRXr8Y+Rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicardoQiu/Artificial-Intelligence/blob/master/NN_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4U--JnNo6gA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6mDu4aDsBfq"
      },
      "source": [
        "**mount GDrive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf3TdsczrzK6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bdnOSAPsNqI"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_shc3sS4sWVm"
      },
      "source": [
        "# **Load Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC_krv42sT_W"
      },
      "source": [
        "data = np.float32(np.load('/content/drive/My Drive/Data/train.npy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE4-AsVjtIWZ"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SMmTq2guUU7"
      },
      "source": [
        "split_ratio = 0.2\n",
        "total_num = data.shape[0]\n",
        "val_num = int(total_num*split_ratio)\n",
        "train_set, val_set = torch.utils.data.random_split(data, [total_num-val_num, val_num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so8bR--wzl9n"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "seq_len = 7\n",
        "n_features = 1\n",
        "batch_size = 16\n",
        "epochs = 1000\n",
        "lr = 2e-4\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlWbH-1numCh"
      },
      "source": [
        "train_dl = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3COdcx8fgNtf"
      },
      "source": [
        "# **Proposed RNN-based Autoencoder Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng2trIyFpvNi"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, seq_len, n_features=1, embedding_dim=64):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.seq_len, self.n_features = seq_len, n_features\n",
        "        self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
        "\n",
        "        self.rnn1 = nn.LSTM(\n",
        "        input_size=n_features,\n",
        "        hidden_size=self.hidden_dim,\n",
        "        num_layers=1,\n",
        "        batch_first=True\n",
        "        )\n",
        "\n",
        "        self.rnn2 = nn.LSTM(\n",
        "        input_size=self.hidden_dim,\n",
        "        hidden_size=embedding_dim,\n",
        "        num_layers=1,\n",
        "        batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b_size = x.size(0)\n",
        "        x = x.reshape((b_size, self.seq_len, self.n_features))\n",
        "        x, (_, _) = self.rnn1(x)\n",
        "        x, (hidden_n, _) = self.rnn2(x)\n",
        "        return hidden_n.reshape((b_size, self.n_features, self.embedding_dim))\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, seq_len, input_dim=64, n_features=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq_len, self.input_dim = seq_len, input_dim\n",
        "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
        "\n",
        "        self.rnn1 = nn.LSTM(\n",
        "        input_size=input_dim,\n",
        "        hidden_size=input_dim,\n",
        "        num_layers=1,\n",
        "        batch_first=True\n",
        "        )\n",
        "\n",
        "        self.rnn2 = nn.LSTM(\n",
        "        input_size=input_dim,\n",
        "        hidden_size=self.hidden_dim,\n",
        "        num_layers=1,\n",
        "        batch_first=True\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x, (_, _) = self.rnn1(x)\n",
        "        x, (_, _) = self.rnn2(x)\n",
        " \n",
        "        return self.output_layer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgR14nfzrw64"
      },
      "source": [
        "class LSTMAE(nn.Module):\n",
        "    def __init__(self, seq_len, n_features, embedding_dim=64, device='cpu'):\n",
        "        super(LSTMAE, self).__init__()\n",
        "        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
        "        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
        "\n",
        "        self.seq_len, self.n_features = seq_len, n_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.repeat(1, self.seq_len, self.n_features)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0KtbjaMgZF4"
      },
      "source": [
        "# **Train the proposed neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaJ5ontH1zKV"
      },
      "source": [
        "lstmAE = LSTMAE(seq_len, n_features=n_features, device=device)\n",
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = optim.Adam(lstmAE.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9uk-GbVqO3W"
      },
      "source": [
        "def train(model, train_dl, criterion, optimizer, device):\n",
        "    epoch_loss = 0.0\n",
        "    model.train()\n",
        "    for seq in train_dl:\n",
        "        x = seq.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        x_recon = model(x)\n",
        "\n",
        "        loss = criterion(x_recon, x)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    return epoch_loss / len(train_dl.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbA-6udju58w"
      },
      "source": [
        "def test(model, val_dl, criterion, device):\n",
        "    epoch_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for seq in val_dl:\n",
        "            x = seq.to(device)\n",
        "            x_recon = model(x)\n",
        "            loss = criterion(x_recon, x)\n",
        "            epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(val_dl.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wt_EJDR0etu"
      },
      "source": [
        "Folder = 'drive/MyDrive/cache'\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "if not os.path.exists(Folder):\n",
        "    os.makedirs(Folder)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = train(lstmAE, train_dl, criterion, optimizer, device)\n",
        "    val_loss = test(lstmAE, val_dl, criterion, device)\n",
        "    print(f\"epoch:{epoch+1} [train loss: {train_loss} Val loss: {val_loss}]\")\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(lstmAE.state_dict(), os.path.join(Folder, 'best-model.pt'))\n",
        "    \n",
        "    if epoch % 99 == 0:\n",
        "        path = os.path.join(Folder, f'lstmAE_{epoch}.pt')\n",
        "        torch.save(lstmAE.state_dict(), path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L525N_hZgn1j"
      },
      "source": [
        "# **Evaluate the proposed trained neural network on Canonical Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEf6JAb6U96o"
      },
      "source": [
        "seq_len = 7\n",
        "n_features = 1\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "lstmAE = LSTMAE(seq_len, n_features=n_features, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wx5iI8K-HiL"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/My Drive/Data/10Pipes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42IjwyK6-pRK"
      },
      "source": [
        "M1 = test_data['M1']\n",
        "M1_mean = M1.mean()\n",
        "M1_std = M1.std()\n",
        "M1_norm = (M1-M1_mean) / M1_std\n",
        "M1_norm = M1_norm.values\n",
        "print(M1_norm.shape)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(M1_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnpC1na_CPV9"
      },
      "source": [
        "trained_weights_path = '/content/drive/My Drive/cache/best-model.pt'\n",
        "lstmAE.load_state_dict(torch.load(trained_weights_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQXCervO_gtt"
      },
      "source": [
        "window_size = 7\n",
        "stride = 1\n",
        "sq_T = M1_norm.shape[0]\n",
        "num_seq = (sq_T - window_size) // stride + 1\n",
        "threshold = 1e-2\n",
        "\n",
        "indices = (np.arange(window_size) + np.arange(0, num_seq, stride).reshape(-1,1)).reshape(-1,)\n",
        "sliding_windows = M1_norm[indices].reshape(-1, window_size, 1)\n",
        "print(sliding_windows.shape)\n",
        "sliding_windows = torch.tensor(sliding_windows, dtype=torch.float32).to(device)\n",
        "out = lstmAE(sliding_windows)\n",
        "error = ((out - sliding_windows)**2).mean(dim=(1,2)).detach().cpu().numpy() \n",
        "print(error.shape)\n",
        "\n",
        "print(error.min(), error.mean(), error.std())\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.axhline(y=threshold, color='r', linestyle='-')\n",
        "plt.plot(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnqE1iHUg-2K"
      },
      "source": [
        "# **Find the candidates and post-process the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "I0cM1R2LN9ao"
      },
      "source": [
        "candidate_windows = np.where(error > threshold)[0]\n",
        "seg_candidates = np.split(candidate_windows, np.where(np.diff(candidate_windows)>2)[0] + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0daoLgJaudJ"
      },
      "source": [
        "**Visualize the Segmented Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdG-dzSXaS40"
      },
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "plt.plot(M1_norm, label=\"raw data\")\n",
        "\n",
        "plot_indices = indices.reshape(-1, window_size)\n",
        "\n",
        "plt.plot(plot_indices[int(seg_candidates[0].mean())], [-1]*window_size, color='red', linewidth=4, label='Bounding Box')\n",
        "\n",
        "for cand in seg_candidates:\n",
        "    window = plot_indices[int(cand.mean())]\n",
        "    plt.plot(window, [-1]*window_size, color='red', linewidth=4)\n",
        "    plt.plot(window, [1]*window_size, color='red', linewidth=4)\n",
        "    plt.plot([window, window], [-1, 1], color='red', linewidth=4)\n",
        "    # plt.plot(window+window_size, [-1]*window_size, color='red', linewidth=4)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}